{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#A01702752 Cristian Espinosa Díaz"
      ],
      "metadata": {
        "id": "B_bkBfN0VOvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Módulo 1 Utilización, procesamiento y visualización de grandes volúmenes de datos (Portafolio Análisis)"
      ],
      "metadata": {
        "id": "Kxc2vI00VPTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalamos pyspark y java"
      ],
      "metadata": {
        "id": "DZLIKarqVlp8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "e3o4mXWDsJ7d",
        "outputId": "3b8f8bb4-a9a2-44c0-c35a-6a03b7f28093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connected to cloud.r-pr\u001b[0m\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to ppa.launc\u001b[0m\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 119 kB in 2s (68.7 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "20 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.4.1-bin-hadoop3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "#Bibliotecas para poder trabajar con Spark\n",
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.4.1//spark-3.4.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.1-bin-hadoop3.tgz\n",
        "#Configuración de Spark con Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "\n",
        "#Estableciendo variable de entorno\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "\n",
        "#Buscando e inicializando la instalación de Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importamos nuestro dataset"
      ],
      "metadata": {
        "id": "mSJaYQglVs_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset escogido fue extraído de [Chicago Data Portal](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if).\n",
        "Este dataset proporciona información sobre datos de accidentes de tráfico en las calles de la ciudad dentro de los límites de la Ciudad de Chicago y bajo la jurisdicción del Departamento de Policía de Chicago (CPD).\n",
        "\n",
        "Estos datos provienen del sistema de informes electrónicos de accidentes (E-Crash) del CPD y se presentan tal como están, sin incluir información personal identificable. Los registros se añaden al portal de datos cuando se finaliza un informe de accidente o cuando se realizan modificaciones en un informe existente en E-Crash.\n",
        "\n",
        "Los datos de E-Crash están disponibles para algunos distritos policiales a partir de 2015, pero los datos de toda la ciudad no están disponibles hasta septiembre de 2017.\n",
        "\n",
        "El objetivo que tendrá el modelo será predecir si un accidente tendrá o no una persona lastimada."
      ],
      "metadata": {
        "id": "3w_1TD2OVzTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "!pwd\n",
        "#put your own path in google drive\n",
        "%cd \"/content/gdrive/MyDrive/Colab Notebooks/Archivos\"\n",
        "!ls"
      ],
      "metadata": {
        "id": "puQfLP7WrFeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44190421-2a2a-4ca6-a3ff-16ef14cc5642"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks/Archivos\n",
            "/content/gdrive/MyDrive/Colab Notebooks/Archivos\n",
            " CNN_Model.png\t\t      part2.csv\t\t\t     'Summary of Weather.csv'\n",
            " Dataset\t\t      part4.csv\t\t\t      titanic.csv\n",
            " FastFoodNutritionMenu.csv    Raisin_Dataset.xlsx\t      Traffic_Crashes_Chicago.csv\n",
            " FastFoodNutritionMenu.xlsx   spark-3.4.1-bin-hadoop3\t      UserCarDataExample.csv\n",
            " Food_Inspections.csv\t      spark-3.4.1-bin-hadoop3.tgz     Vegetables\n",
            " iris.data\t\t      spark-3.4.1-bin-hadoop3.tgz.1   wine.data\n",
            " model.h5\t\t      spark-3.4.1-bin-hadoop3.tgz.2  'winequality-red (1).csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalamos las librerías necesarias para la ejecución del modelo y la preparación de los datos que realizaremos a continuación. A su vez creamos la sesión de Spark y el dataframe inicial."
      ],
      "metadata": {
        "id": "D2O29kBbWqQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.functions import when, col\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import col, expr\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Inicializa una sesión de Spark\n",
        "spark = SparkSession.builder.appName(\"EjemploCSV\").getOrCreate()\n",
        "\n",
        "# Reemplaza 'nombre_del_archivo.csv' con la ruta al archivo CSV\n",
        "nombre_archivo_csv = 'Traffic_Crashes_Chicago.csv'\n",
        "\n",
        "# Lee el archivo CSV y crea un DataFrame\n",
        "data = spark.read.csv(nombre_archivo_csv, header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "CPlG50mLsZad"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imprimimos el esquema para verificar que el datset fue importado con éxito y para determinar que atributos serán relevantes para la predicción.**"
      ],
      "metadata": {
        "id": "2UeF3l36X9_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.printSchema()"
      ],
      "metadata": {
        "id": "XweRYTZdsfrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf08342-2861-41e8-829c-8c16e89cd0da"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CRASH_RECORD_ID: string (nullable = true)\n",
            " |-- RD_NO: string (nullable = true)\n",
            " |-- CRASH_DATE_EST_I: string (nullable = true)\n",
            " |-- CRASH_DATE: string (nullable = true)\n",
            " |-- POSTED_SPEED_LIMIT: integer (nullable = true)\n",
            " |-- TRAFFIC_CONTROL_DEVICE: string (nullable = true)\n",
            " |-- DEVICE_CONDITION: string (nullable = true)\n",
            " |-- WEATHER_CONDITION: string (nullable = true)\n",
            " |-- LIGHTING_CONDITION: string (nullable = true)\n",
            " |-- FIRST_CRASH_TYPE: string (nullable = true)\n",
            " |-- TRAFFICWAY_TYPE: string (nullable = true)\n",
            " |-- LANE_CNT: integer (nullable = true)\n",
            " |-- ALIGNMENT: string (nullable = true)\n",
            " |-- ROADWAY_SURFACE_COND: string (nullable = true)\n",
            " |-- ROAD_DEFECT: string (nullable = true)\n",
            " |-- REPORT_TYPE: string (nullable = true)\n",
            " |-- CRASH_TYPE: string (nullable = true)\n",
            " |-- INTERSECTION_RELATED_I: string (nullable = true)\n",
            " |-- NOT_RIGHT_OF_WAY_I: string (nullable = true)\n",
            " |-- HIT_AND_RUN_I: string (nullable = true)\n",
            " |-- DAMAGE: string (nullable = true)\n",
            " |-- DATE_POLICE_NOTIFIED: string (nullable = true)\n",
            " |-- PRIM_CONTRIBUTORY_CAUSE: string (nullable = true)\n",
            " |-- SEC_CONTRIBUTORY_CAUSE: string (nullable = true)\n",
            " |-- STREET_NO: integer (nullable = true)\n",
            " |-- STREET_DIRECTION: string (nullable = true)\n",
            " |-- STREET_NAME: string (nullable = true)\n",
            " |-- BEAT_OF_OCCURRENCE: integer (nullable = true)\n",
            " |-- PHOTOS_TAKEN_I: string (nullable = true)\n",
            " |-- STATEMENTS_TAKEN_I: string (nullable = true)\n",
            " |-- DOORING_I: string (nullable = true)\n",
            " |-- WORK_ZONE_I: string (nullable = true)\n",
            " |-- WORK_ZONE_TYPE: string (nullable = true)\n",
            " |-- WORKERS_PRESENT_I: string (nullable = true)\n",
            " |-- NUM_UNITS: integer (nullable = true)\n",
            " |-- MOST_SEVERE_INJURY: string (nullable = true)\n",
            " |-- INJURIES_TOTAL: integer (nullable = true)\n",
            " |-- INJURIES_FATAL: integer (nullable = true)\n",
            " |-- INJURIES_INCAPACITATING: integer (nullable = true)\n",
            " |-- INJURIES_NON_INCAPACITATING: integer (nullable = true)\n",
            " |-- INJURIES_REPORTED_NOT_EVIDENT: integer (nullable = true)\n",
            " |-- INJURIES_NO_INDICATION: integer (nullable = true)\n",
            " |-- INJURIES_UNKNOWN: integer (nullable = true)\n",
            " |-- CRASH_HOUR: integer (nullable = true)\n",
            " |-- CRASH_DAY_OF_WEEK: integer (nullable = true)\n",
            " |-- CRASH_MONTH: integer (nullable = true)\n",
            " |-- LATITUDE: double (nullable = true)\n",
            " |-- LONGITUDE: double (nullable = true)\n",
            " |-- LOCATION: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algunas columnas como 'RD_NO' serán eliminadas debido a que la institución al anonimizar los datos por razones de privacidad dejó estas columnas vacías por lo que no tendrán mucha información que aportar al modelo.\n",
        "\n",
        "Posteriormente, se eliminarán columnas como 'CRASH_RECORD_ID' debido a que la información que contienen estas columnas no es relevante para el objetivo del modelo.\n",
        "\n",
        "Solo mantendremos 8 columnas, las cuales son:\n",
        "* TRAFFIC_CONTROL_DEVICE\n",
        "* WEATHER_CONDITION\n",
        "* LIGHTING_CONDITION\n",
        "* FIRST_CRASH_TYPE\n",
        "* TRAFFICWAY_TYPE\n",
        "* ROADWAY_SURFACE_COND\n",
        "* ROAD_DEFECT\n",
        "* INJURIES_TOTAL"
      ],
      "metadata": {
        "id": "O-CQTPvkYSmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to keep\n",
        "columns_to_keep = [\n",
        "    \"TRAFFIC_CONTROL_DEVICE\",\n",
        "    \"WEATHER_CONDITION\",\n",
        "    \"LIGHTING_CONDITION\",\n",
        "    \"FIRST_CRASH_TYPE\",\n",
        "    \"TRAFFICWAY_TYPE\",\n",
        "    \"ROADWAY_SURFACE_COND\",\n",
        "    \"ROAD_DEFECT\",\n",
        "    \"INJURIES_TOTAL\"\n",
        "]\n",
        "\n",
        "selected_data = data.select(*columns_to_keep)\n",
        "selected_data.show()"
      ],
      "metadata": {
        "id": "4MWVIdA2srhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e38f918-eb45-462a-904b-dd714350c7e2"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+-----------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------+\n",
            "|TRAFFIC_CONTROL_DEVICE|WEATHER_CONDITION|  LIGHTING_CONDITION|    FIRST_CRASH_TYPE|     TRAFFICWAY_TYPE|ROADWAY_SURFACE_COND|ROAD_DEFECT|INJURIES_TOTAL|\n",
            "+----------------------+-----------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------+\n",
            "|                 OTHER|            CLEAR|            DAYLIGHT|            REAR END|               OTHER|                 DRY| NO DEFECTS|             1|\n",
            "|        TRAFFIC SIGNAL|            CLEAR|            DAYLIGHT|PARKED MOTOR VEHICLE|DIVIDED - W/MEDIA...|                 DRY| NO DEFECTS|             0|\n",
            "|           NO CONTROLS|            CLEAR|            DAYLIGHT|        PEDALCYCLIST|         NOT DIVIDED|                 DRY| NO DEFECTS|             1|\n",
            "|           NO CONTROLS|            CLEAR|            DAYLIGHT|          PEDESTRIAN|             ONE-WAY|                 DRY| NO DEFECTS|             1|\n",
            "|           NO CONTROLS|            CLEAR|            DAYLIGHT|        FIXED OBJECT|               OTHER|                 DRY| NO DEFECTS|             0|\n",
            "|        TRAFFIC SIGNAL|            CLEAR|            DAYLIGHT|             TURNING|         NOT DIVIDED|             UNKNOWN|    UNKNOWN|             0|\n",
            "|           NO CONTROLS|            CLEAR|DARKNESS, LIGHTED...|            REAR END|             ONE-WAY|                 DRY| NO DEFECTS|             0|\n",
            "|           NO CONTROLS|            CLEAR|            DAYLIGHT|               ANGLE|               OTHER|                 DRY| NO DEFECTS|             0|\n",
            "|        TRAFFIC SIGNAL|            CLEAR|DARKNESS, LIGHTED...|             TURNING|            FOUR WAY|                 DRY| NO DEFECTS|             0|\n",
            "|           NO CONTROLS|            CLEAR|            DARKNESS|            REAR END|             ONE-WAY|                 DRY| NO DEFECTS|             0|\n",
            "|           NO CONTROLS|             SNOW|DARKNESS, LIGHTED...|               ANGLE|         PARKING LOT|       SNOW OR SLUSH| NO DEFECTS|             0|\n",
            "|           NO CONTROLS|            CLEAR|            DAYLIGHT|SIDESWIPE SAME DI...|         PARKING LOT|                 DRY| NO DEFECTS|             0|\n",
            "|           NO CONTROLS|            CLEAR|            DAYLIGHT|SIDESWIPE SAME DI...|               OTHER|                 DRY| NO DEFECTS|             0|\n",
            "|           NO CONTROLS|          UNKNOWN|             UNKNOWN|               ANGLE|         PARKING LOT|             UNKNOWN|    UNKNOWN|             0|\n",
            "|        TRAFFIC SIGNAL|            CLEAR|            DARKNESS|SIDESWIPE OPPOSIT...|         NOT DIVIDED|             UNKNOWN|    UNKNOWN|             0|\n",
            "|           NO CONTROLS|            CLEAR|            DAYLIGHT|            REAR END|             ONE-WAY|                 DRY| NO DEFECTS|             0|\n",
            "|           NO CONTROLS|            CLEAR|            DAYLIGHT|SIDESWIPE OPPOSIT...|             ONE-WAY|                 DRY| NO DEFECTS|             0|\n",
            "|     STOP SIGN/FLASHER|            CLEAR|DARKNESS, LIGHTED...|             TURNING|         PARKING LOT|                 DRY| NO DEFECTS|             0|\n",
            "|           NO CONTROLS|             RAIN|            DAYLIGHT|        FIXED OBJECT|DIVIDED - W/MEDIA...|                 WET| NO DEFECTS|             0|\n",
            "|        TRAFFIC SIGNAL|            CLEAR|            DAYLIGHT|            REAR END|      T-INTERSECTION|                 DRY| NO DEFECTS|             0|\n",
            "+----------------------+-----------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos aseguramos de eliminar las filas con información faltante por medio de la función 'drop.na()'"
      ],
      "metadata": {
        "id": "fpvtDnrVZmGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_data = selected_data.dropna()"
      ],
      "metadata": {
        "id": "N9ys026EHgwy"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertimos las variables categóricas en númericas por medio de la función 'StringIndexer'. A su vez, convertimos la columna de 'INJURIES_TOTAL' de entero a booleana."
      ],
      "metadata": {
        "id": "DXfGuinXZxpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to be indexed\n",
        "columns_to_index = [\n",
        "    \"TRAFFIC_CONTROL_DEVICE\",\n",
        "    \"WEATHER_CONDITION\",\n",
        "    \"LIGHTING_CONDITION\",\n",
        "    \"FIRST_CRASH_TYPE\",\n",
        "    \"TRAFFICWAY_TYPE\",\n",
        "    \"ROADWAY_SURFACE_COND\",\n",
        "    \"ROAD_DEFECT\",\n",
        "]\n",
        "\n",
        "# Create a list of StringIndexers\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=col, outputCol=f\"{col}_LABELED\", handleInvalid=\"skip\")\n",
        "    for col in columns_to_index\n",
        "]\n",
        "\n",
        "# Apply the transformations\n",
        "indexed_df = selected_data\n",
        "\n",
        "for indexer in indexers:\n",
        "    indexed_df = indexer.fit(indexed_df).transform(indexed_df)\n"
      ],
      "metadata": {
        "id": "UVgzpF0Gu9z4"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use withColumn to create a boolean column based on the condition\n",
        "indexed_df = indexed_df.withColumn(\"INJURIES_TOTAL_LABELED\", F.when(indexed_df[\"INJURIES_TOTAL\"] == 0, 0).otherwise(1))"
      ],
      "metadata": {
        "id": "3VymsPQggJse"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimimos el esquema nuevamente para verificar que nuestras columnas con los datos en formato numérico se crearon con éxito, estas columnas poseen la terminación '_LABELED'."
      ],
      "metadata": {
        "id": "WpTgdF4dZ_NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indexed_df.printSchema()"
      ],
      "metadata": {
        "id": "MqZgEREfwkw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d0c428-42e2-4090-d2d8-7487b6b2bb20"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- TRAFFIC_CONTROL_DEVICE: string (nullable = true)\n",
            " |-- WEATHER_CONDITION: string (nullable = true)\n",
            " |-- LIGHTING_CONDITION: string (nullable = true)\n",
            " |-- FIRST_CRASH_TYPE: string (nullable = true)\n",
            " |-- TRAFFICWAY_TYPE: string (nullable = true)\n",
            " |-- ROADWAY_SURFACE_COND: string (nullable = true)\n",
            " |-- ROAD_DEFECT: string (nullable = true)\n",
            " |-- INJURIES_TOTAL: integer (nullable = true)\n",
            " |-- TRAFFIC_CONTROL_DEVICE_LABELED: double (nullable = false)\n",
            " |-- WEATHER_CONDITION_LABELED: double (nullable = false)\n",
            " |-- LIGHTING_CONDITION_LABELED: double (nullable = false)\n",
            " |-- FIRST_CRASH_TYPE_LABELED: double (nullable = false)\n",
            " |-- TRAFFICWAY_TYPE_LABELED: double (nullable = false)\n",
            " |-- ROADWAY_SURFACE_COND_LABELED: double (nullable = false)\n",
            " |-- ROAD_DEFECT_LABELED: double (nullable = false)\n",
            " |-- INJURIES_TOTAL_LABELED: integer (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ingresamos todas las variables independientes en un vector usando 'VectorAssembler', posteriormente se integran al dataframe utilizando un 'transform'."
      ],
      "metadata": {
        "id": "QU3BBgdKaWXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have feature columns named \"feature1,\" \"feature2,\" etc.\n",
        "feature_columns = [\"TRAFFIC_CONTROL_DEVICE_LABELED\", \"WEATHER_CONDITION_LABELED\", \"LIGHTING_CONDITION_LABELED\", \"FIRST_CRASH_TYPE_LABELED\", \"TRAFFICWAY_TYPE_LABELED\", \"ROADWAY_SURFACE_COND_LABELED\", \"ROAD_DEFECT_LABELED\"]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"Independent Features\")\n",
        "result = assembler.transform(indexed_df)"
      ],
      "metadata": {
        "id": "2l7LLa9P5dFT"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construimos nuestro modelo de regresión mediante la selección de la columna donde integramos los valores de las variables independientes y la columna que representa la variable dependiente."
      ],
      "metadata": {
        "id": "q4h_KR4wa7Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = result.select(\"Independent features\", \"INJURIES_TOTAL_LABELED\")\n",
        "final_data.show()"
      ],
      "metadata": {
        "id": "_5WGnt476HN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8efea1eb-e5c7-4357-d9dc-7f6f4a3cdb89"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------------------+\n",
            "|Independent features|INJURIES_TOTAL_LABELED|\n",
            "+--------------------+----------------------+\n",
            "|(7,[0,3,4],[4.0,1...|                     1|\n",
            "| (7,[0,4],[1.0,1.0])|                     0|\n",
            "|       (7,[3],[7.0])|                     1|\n",
            "| (7,[3,4],[6.0,2.0])|                     1|\n",
            "| (7,[3,4],[5.0,6.0])|                     0|\n",
            "|[1.0,0.0,0.0,3.0,...|                     0|\n",
            "|(7,[2,3,4],[1.0,1...|                     0|\n",
            "| (7,[3,4],[4.0,6.0])|                     0|\n",
            "|[1.0,0.0,1.0,3.0,...|                     0|\n",
            "|(7,[2,3,4],[2.0,1...|                     0|\n",
            "|[0.0,3.0,1.0,4.0,...|                     0|\n",
            "| (7,[3,4],[2.0,3.0])|                     0|\n",
            "| (7,[3,4],[2.0,6.0])|                     0|\n",
            "|[0.0,2.0,3.0,4.0,...|                     0|\n",
            "|[1.0,0.0,2.0,8.0,...|                     0|\n",
            "| (7,[3,4],[1.0,2.0])|                     0|\n",
            "| (7,[3,4],[8.0,2.0])|                     0|\n",
            "|[2.0,0.0,1.0,3.0,...|                     0|\n",
            "|[0.0,1.0,0.0,5.0,...|                     0|\n",
            "|(7,[0,3,4],[1.0,1...|                     0|\n",
            "+--------------------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Del conjunto total de datos realizamos una división entre entrenamiento y prueba con la función 'randomSplit'."
      ],
      "metadata": {
        "id": "WE3TA_3abxib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = final_data.randomSplit([0.7, 0.3], seed=123)"
      ],
      "metadata": {
        "id": "cJHhW9FA6eoC"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos el modelo de regresión logística, en este caso será booleana para predecir si un accidente tandrá heridos o no."
      ],
      "metadata": {
        "id": "eJaWxd1dcCPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a logistic regression model\n",
        "model = LogisticRegression(labelCol=\"INJURIES_TOTAL_LABELED\", featuresCol=\"Independent features\", maxIter=100, regParam=0.01)\n"
      ],
      "metadata": {
        "id": "ZDqVwkUV6hWQ"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.fit(train_data)"
      ],
      "metadata": {
        "id": "KyGVIB2i6il2"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos las predicciones y usamos a 'MulticlassClassificationEvaluator' para evaluar nuestro modelo por medio de las métricas de 'Accuracy' y 'F1 Score'."
      ],
      "metadata": {
        "id": "9NW0XCZMhSr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)"
      ],
      "metadata": {
        "id": "NE3oOdT66kZ3"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"INJURIES_TOTAL_LABELED\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "evaluator2 = MulticlassClassificationEvaluator(labelCol=\"INJURIES_TOTAL_LABELED\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "f1_score = evaluator2.evaluate(predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1_score)"
      ],
      "metadata": {
        "id": "HfxnXQYP6ns_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90fa5141-5fbf-4968-81d8-7a29d95284e5"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8608367478973474\n",
            "F1 Score: 0.8010057371672922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy (Precisión):\n",
        "\n",
        "* El valor de precisión es 0.8608, lo que significa que el modelo de regresión logística es capaz de predecir correctamente el resultado en aproximadamente el 86.08% de los casos.\n",
        "\n",
        "* Un alto valor de precisión sugiere que el modelo es efectivo en la clasificación de los datos y en la toma de decisiones correctas.\n",
        "\n",
        "F1 Score:\n",
        "\n",
        "* El valor del puntaje F1 es 0.8010, lo que indica un buen equilibrio entre la precisión y la exhaustividad (recall) del modelo.\n",
        "\n",
        "* El puntaje F1 es una métrica que combina tanto la precisión como la exhaustividad en una sola métrica. Proporciona una medida de la precisión del modelo teniendo en cuenta tanto los falsos positivos como los falsos negativos.\n",
        "\n",
        "* Un valor de F1 Score de 0.8010 sugiere que el modelo es capaz de lograr un equilibrio entre minimizar tanto los falsos positivos como los falsos negativos, lo que es deseable en muchas aplicaciones.\n",
        "\n",
        "En resumen, estos resultados indican que el modelo de regresión logística tiene un buen rendimiento en términos de precisión y un equilibrio razonable entre precisión y exhaustividad, lo que sugiere que es un modelo sólido para la predicción de si un accidente tendrá lesionados con base a las variables independientes."
      ],
      "metadata": {
        "id": "I_eTYK12h2TI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos predicciones para observar el funcionamiento del modelo obtenido.\n",
        "\n",
        "Las columnas rawPrediction y probability son componentes esenciales de un modelo de regresión logística y se utilizan para evaluar la confianza del modelo en sus predicciones y para obtener las probabilidades de pertenencia a una clase en una tarea de clasificación binaria."
      ],
      "metadata": {
        "id": "a1iicGcai17X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_result = model.evaluate(test_data)\n",
        "prediction_result.predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni7lLp-4cMtY",
        "outputId": "42b2e364-46f4-48f0-e81a-088eade6d5d6"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------------------+--------------------+--------------------+----------+\n",
            "|Independent features|INJURIES_TOTAL_LABELED|       rawPrediction|         probability|prediction|\n",
            "+--------------------+----------------------+--------------------+--------------------+----------+\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "|           (7,[],[])|                     0|[2.40560599419750...|[0.91725379088488...|       0.0|\n",
            "+--------------------+----------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos nuestro modelo para cargarlo después, en caso de ser necesario\n",
        "model.save(\"TrafficInjuries_ClassificationModel.dt\")"
      ],
      "metadata": {
        "id": "3PCBiW9C_bMw"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spark.stop()"
      ],
      "metadata": {
        "id": "q9GbA7nK9XRN"
      },
      "execution_count": 114,
      "outputs": []
    }
  ]
}